import os
from langchain_community.document_loaders import TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_ollama import OllamaEmbeddings
from langchain_community.vectorstores import FAISS

def load_documents_for_character(character_folder):
    """ØªØ­Ù…ÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø§Ù„Ù†ØµÙŠØ© Ù…Ù† Ù…Ø¬Ù„Ø¯ Ø´Ø®ØµÙŠØ© Ù…Ø¹ÙŠÙ†Ø©"""
    documents = []
    if not os.path.exists(character_folder):
        print(f"âŒ Folder not found: {character_folder}")
        return documents

    for filename in os.listdir(character_folder):
        if filename.endswith(".txt"):
            path = os.path.join(character_folder, filename)
            try:
                loader = TextLoader(path, encoding='utf-8')
                docs = loader.load()
                documents.extend(docs)
                print(f"âœ… Loaded {len(docs)} docs from {filename}")
            except Exception as e:
                print(f"âŒ Failed to load {filename}: {str(e)}")
    return documents

def build_index_for_character(character_name, base_data="data", base_index="indexes"):
    """Ø¨Ù†Ø§Ø¡ ÙÙ‡Ø±Ø³ Ø§Ù„Ø¨Ø­Ø« Ù„Ù…Ø¬Ù„Ø¯ Ø´Ø®ØµÙŠØ© Ù…Ø¹ÙŠÙ†Ø©"""
    folder_path = os.path.join(base_data, character_name)
    docs = load_documents_for_character(folder_path)
    if not docs:
        print(f"âŒ No documents found for {character_name}")
        return

    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    chunks = splitter.split_documents(docs)

    embeddings = OllamaEmbeddings(model="all-minilm")
    index = FAISS.from_documents(chunks, embedding=embeddings)

    # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ indexes Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ù‹Ø§
    os.makedirs(base_index, exist_ok=True)
    
    save_path = os.path.join(base_index, character_name)
    index.save_local(save_path)
    print(f"ğŸ“¦ Saved vector index for {character_name} at {save_path}")

def discover_character_folders(base_data="data"):
    """Ø§ÙƒØªØ´Ø§Ù Ø¬Ù…ÙŠØ¹ Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„Ø´Ø®ØµÙŠØ§Øª ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§"""
    if not os.path.exists(base_data):
        print(f"âŒ Data folder not found: {base_data}")
        return []

    # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª ÙÙŠ data ÙˆØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ù…Ù„ÙØ§Øª
    character_folders = [
        name for name in os.listdir(base_data) 
        if os.path.isdir(os.path.join(base_data, name))
    ]
    
    print(f"ğŸ” Discovered {len(character_folders)} character folders")
    return character_folders

if __name__ == "__main__":
    # Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§ Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø«Ø§Ø¨ØªØ©
    characters = discover_character_folders()
    
    if not characters:
        print("âŒ No character folders found in 'data' directory")
    else:
        print("ğŸ“‚ Character folders to process:", ", ".join(characters))
        
        for name in characters:
            print(f"\nğŸ” Indexing {name}...")
            build_index_for_character(name)
        
        print("\nğŸ‰ All characters processed successfully!")